{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import checkpoint2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from IPython.display import HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = pd.read_csv(\"uber_cleaned.csv\").dropna().astype({'Invited': 'int32', \"Unfair\": 'int32'})\n",
    "lyft = pd.read_csv(\"lyft_cleaned.csv\").astype({'Invited': 'int32'})\n",
    "uber['# Reviews By User'] = pd.to_numeric(uber['# Reviews By User'], errors='coerce')\n",
    "lyft[\"# Reviews By User\"] = pd.to_numeric(lyft['# Reviews By User'], errors='coerce')\n",
    "uber = uber.dropna(subset=['# Reviews By User'])\n",
    "lyft = lyft.dropna(subset=['# Reviews By User'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "sentiment = checkpoint2.get_weighed_sentiment_counts(checkpoint2.get_sentiment_and_counts(uber))\n",
    "class SentimentTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Review Body\"] = checkpoint2.preprocess_reviews(X)\n",
    "        X['Sentiment'] = [sum([sentiment[word] if word in sentiment else 0 for word in str(review).split()]) for review in X[\"Review Body\"]]\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "multinomial_transformer = ColumnTransformer([\n",
    "    ('title_vect', TfidfVectorizer(max_df=0.5, max_features=18, min_df=0, stop_words='english', sublinear_tf=True, use_idf=False), 'Review Title'), \n",
    "    ('body_vect', TfidfVectorizer(max_df=0.5, max_features=144, min_df=0, stop_words=None, sublinear_tf=True, use_idf=True), 'Review Body')\n",
    "])\n",
    "\n",
    "multinomial_classifier = Pipeline([\n",
    "    ('selector', multinomial_transformer),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "labeled = uber[uber.Unfair.notnull()]\n",
    "X_labeled = labeled.loc[:, labeled.columns != 'Unfair']\n",
    "y_labeled = labeled['Unfair']\n",
    "\n",
    "# labeled.head()\n",
    "# tmp = multinomial_transformer.fit_transform(X_labeled, y_labeled)\n",
    "# checkpoint2.validate_model(multinomial_classifier, 5, X_labeled, y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90082645, 0.60052632, 0.73309942, 0.65092732, 0.90082645])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = GridSearchCV(multinomial_classifier, {'selector__title_vect__use_idf': [False], 'selector__body_vect__use_idf': [True], \n",
    "#                                             'selector__body_vect__max_features': [144], \n",
    "#                                             'selector__title_vect__max_features': [18],\n",
    "#                                             'selector__body_vect__max_df': [0.5],\n",
    "#                                             'selector__body_vect__min_df': [0.0],\n",
    "#                                             'selector__title_vect__max_df': [0.5],\n",
    "#                                             'selector__title_vect__min_df': [0.0],\n",
    "#                                             'selector__title_vect__stop_words': ['english', None],\n",
    "#                                             'selector__body_vect__stop_words': ['english', None],\n",
    "#                                             'selector__title_vect__sublinear_tf': [True, False],\n",
    "#                                             'selector__body_vect__sublinear_tf': [True, False],\n",
    "#                                             'clf__alpha': [6.0]}\n",
    "#                                             , n_jobs=-1, refit=True).fit(X_labeled, y_labeled)\n",
    "\n",
    "from pprint import pprint\n",
    "checkpoint2.validate_model(multinomial_classifier, 5, X_labeled, y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('sentiment', SentimentTransformer()),\n",
    "    ('selector', make_column_transformer((MinMaxScaler(), make_column_selector(dtype_include=np.number))))\n",
    "])\n",
    "\n",
    "svm_classifier = Pipeline([\n",
    "    ('selector', numerical_transformer),\n",
    "    ('clf', SVC(C=1.0, kernel='poly', degree=4, gamma='auto', coef0=0.0, probability=True, class_weight=None, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "def perform_grid_search(model, params, splits=5, jobs=3, X=X_labeled):\n",
    "    clf = GridSearchCV(model, param_grid=params, refit=True, cv=splits, n_jobs=jobs, verbose=3).fit(X, y_labeled)\n",
    "    pprint(clf.best_params_)\n",
    "    pprint(clf.best_score_)\n",
    "    # pprint(checkpoint2.validate_model(model, splits, X, y_labeled))\n",
    "\n",
    "# clf = GridSearchCV(SVC(), {\n",
    "#     'C': np.linspace(0, 1.5, 10),\n",
    "#     'kernel': ['poly'],\n",
    "#     'degree': [4, 5],\n",
    "#     'gamma': ['auto', 'scale'],\n",
    "#     'coef0': [0.0],\n",
    "#     'probability': [True],\n",
    "#     'class_weight': [None, 'balanced'],\n",
    "#     'random_state': [RANDOM_STATE]\n",
    "# }, n_jobs=3, refit=True).fit(numerical_transformer.fit_transform(X_labeled), y_labeled)\n",
    "\n",
    "# checkpoint2.validate_model(svm_classifier, 5, X_labeled, y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = Pipeline([\n",
    "    ('selector', numerical_transformer),\n",
    "    ('clf', DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_split=0.325, max_features='sqrt', random_state=RANDOM_STATE, class_weight=None))\n",
    "])\n",
    "\n",
    "# perform_grid_search(DecisionTreeClassifier(), {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'splitter': ['best'],\n",
    "#     'min_samples_split': np.linspace(0.1, 0.4, 5),\n",
    "#     'max_features': ['sqrt'],\n",
    "#     'random_state': [RANDOM_STATE],\n",
    "#     'class_weight': [None, 'balanced'],\n",
    "# }, 5, 3, X=numerical_transformer.fit_transform(X_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2699, 14)\n",
      "(2699, 14)\n"
     ]
    }
   ],
   "source": [
    "# pd.concat([uber, lyft]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "distorsions = []\n",
    "both = pd.concat([uber, lyft]).iloc[:, uber.columns != 'Unfair']\n",
    "X_numerical = numerical_transformer.fit_transform(both)\n",
    "# for k in range(2, 20):\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init='auto')\n",
    "#     kmeans.fit(X_numerical)\n",
    "#     distorsions.append(kmeans.inertia_)\n",
    "#     print(\"done with \", k)\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "# plt.plot(range(2, 20), distorsions)\n",
    "# plt.grid(True)\n",
    "# plt.title('Elbow curve')\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, max_iter=1000, random_state=RANDOM_STATE, n_init='auto').fit_predict(X_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(kmeans\u001b[39m.\u001b[39;49mshape, X_labeled\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(kmeans.shape, X_labeled.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
